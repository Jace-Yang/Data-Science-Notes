## 概述

对用户而言，推荐系统是一种帮助用户快速发现有用信息的工具，对公司而言，一种帮助用户快速发现有用信息的工具

目前工业界常用的推荐系统分为召回、排序两个模块，召回阶段负责将海量的候选集快速缩小为几万到几千的规模；而排序层则负责对缩小后的候选集进行精准排序。

• **召回层：** 待计算的候选集合大、计算速度快、模型简单、特征较少，尽量让用户感兴趣的物品在这个阶段能够被快速召回，即保证相关物品的召回率

• **排序层：** 首要目标是得到精准的排序结果。需要处理的物品数量少，可以利用较多的特征，使用比较复杂的模型

对于召回层而言，目前常用的召回技术包括多路召回、Embedding召回等等；对于排序层而言，常用的召回技术包括逻辑回归、因子分解机等

## 矩阵分解

矩阵分解算法将 m×n 维的共享矩阵R分解成 m×k 维的用户矩阵U和 k×n 维的物品矩阵V相乘的形式。 其中m是用户数量，n是物品数量，k是隐向量维度
$$
p_{i,j}=\sum _k u_{i,k}*v_{k, j}
$$
使用传统的SVD分解的方法需要对稀疏矩阵的缺失值进行补全，这种方法计算复杂度高，且补全值不精确，无法使用。常用的矩阵分解方法是给定用户矩阵于物品矩阵的初值，转化矩阵分解问题为最优化问题，通过梯度下降的方法进行求解
$$
SSE=\sum_{i,j}e_{i,j}^2=\sum_{i,j}(r_{i,j}-\sum _k u_{i,k}*v_{k, j})^2
$$
在实际应用中，有些固有的属性和用户物品无关， 而用户也有些属性和物品无关， 物品也有些属性和用户无关。 在基础模型中加入偏置项， 可以消除用户和物品打分的偏差
$$
\hat p_{i,j}=\mu + b_u + b_i + \sum _k u_{i,k}*v_{k, j}
$$
• $\mu$ : 训练集中所有记录的评分的全局平均数

• $b_u$: 用户偏差系数， 可以使用用户u给出的所有评分的均值， 也可以当做训练参数

• $b_i$ : 物品偏差系数， 可以使用物品i收到的所有评分的均值， 也可以当做训练参数

矩阵分解算法相比协同过滤方法而言，泛化能力强，在一定程度上解决了矩阵稀疏问题，同时仅需要储存用户矩阵于物品矩阵，空间复杂度有所降低，同时可以学习到一些隐特征；但是矩阵分解算法没有用到用户属性和物品属性，损失了部分有效信息