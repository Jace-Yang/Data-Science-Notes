## 文本分类基础

文本数据属于非结构化数据，对于非结构化数据的处理，首先要转化为结构化数据，常用转化方式有以下四种

• One-hot编码：将每一个单词使用一个离散的向量表示。具体将每个字/词编码一个索引，然后根据索引进行赋值

• Bag of Words：每个文档的字/词可以使用其出现次数来进行表示

• N-gram：与Bag of Words策略类似，加入了相邻单词组合成为的新单词（组合数为N），并进行计数

• TF-IDF：TF代表词语频率，IDF代表逆文档频率

​	TF = 该词语在当前文档出现的次数 / 当前文档中词语的总数

​	IDF = log (文档总数 / 出现该词语的文档总数)

通过以上四种方式将非结构化文本数据转化为结构化数据后，构建机器学习分类模型，例如逻辑回归、决策树、支持向量机等，可以预测不同文档所属类别

## FastText

FastText是Facebook提出的一种典型的深度学习词向量的表示方法，它非常简单通过Embedding层将单词映射到稠密空间，然后将句子中所有的单词在Embedding空间中进行平均，进而完成分类操作。

一般情况下，使用fastText进行文本分类的同时也会产生词的embedding，即embedding是fastText分类的产物。

fastText模型有三层：输入层、隐含层、输出层（Hierarchical Softmax），输入是多个单词及其n-gram特征，这些特征用来表示单个文档，输出是文档对应的类标，隐含层都是对多个词向量的叠加平均。

<img src="https://pic2.zhimg.com/80/v2-7f38f23e98ee89d21fd16e34d5f07d69_720w.jpg" alt="img" style="zoom:67%;" />