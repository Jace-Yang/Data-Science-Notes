## 概述

对用户而言，推荐系统是一种帮助用户快速发现有用信息的工具，对公司而言，一种帮助用户快速发现有用信息的工具

目前工业界常用的推荐系统分为召回、排序两个模块，召回阶段负责将海量的候选集快速缩小为几万到几千的规模；而排序层则负责对缩小后的候选集进行精准排序。

• **召回层：** 待计算的候选集合大、计算速度快、模型简单、特征较少，尽量让用户感兴趣的物品在这个阶段能够被快速召回，即保证相关物品的召回率

• **排序层：** 首要目标是得到精准的排序结果。需要处理的物品数量少，可以利用较多的特征，使用比较复杂的模型

对于召回层而言，目前常用的召回技术包括多路召回、Embedding召回等等；对于排序层而言，常用的召回技术包括逻辑回归、因子分解机等

## 协同过滤

协同过滤算法是推荐系统最经典、最常用的算法，基本思想是根据用户之前的喜好以及其他兴趣相近的用户的选择来给用户推荐物品，一般是仅仅基于用户的行为数据, 而不依赖于物品自身特征或者用户的任何附加属性信息。

协同过滤的核心问题是确定用户-物品矩阵，这个矩阵表示用户对不同物品的评分或者是否购买，通常是稀疏的

• 基于用户的协同过滤(UserCF)：给用户推荐和他之前兴趣相似的其他用户喜欢的物品

• 基于物品的系统过滤(ItemCF)：给用户推荐和他之前喜欢的物品相似的物品

相似度度量：

• Jaccard similarity: 两个用户 u 和 v 交互商品交集的数量占这两个用户交互商品并集的数量的比例，无法反映用户评分

• Cosine similarity: 使用cos函数度量两个用户的距离，未评分的项目有误差

• Pearson correlation: 标准化后度量cosine距离

### UserCF

1. 找到和目标用户兴趣相似的集合(Top K)
2. 找到这个集合中的用户喜欢的， 且目标用户没有听说过的物品推荐给目标用户

预测用户i对物品j的评分，选取相似度最高的topK用户对物品的评分做加权平均

此处减去用户k的平均值是考虑到不同用户评分标准不一致的情况
$$
P_{i,j}=\bar R_i + \frac{\sum_{k=1}^{K} S_{i,k}(R_{k,j}-\bar R_k)}{\sum_{k=1}^{K} S_{i,k}}
$$
适用场景：

UserCF在线计算用户之间的相似度，适用于用户少、物品多、时效性强的场合，可能发现用户潜在喜好但自己尚未察觉的物品

### ItemCF

1. 计算物品之间的相似度

2. 根据物品的相似度和用户的历史行为给用户生成推荐列表

$$
P_{i,j}=\bar R_j + \frac{\sum_{k=1}^{K} S_{j,k}(R_{i,k}-\bar R_k)}{\sum_{k=1}^{K} S_{j,k}}
$$

适用场景：

ItemCF离线计算物品相似度矩阵，适用于物品少、用户多、用户兴趣稳定的场合

### 评价指标

用户真实喜好物品集合为$True(u)$，预测用户喜好物品集合为$Pred(u)$

• 召回率：$\frac{|Pred(u)\cap True(u)|}{|True(u)|}$

• 准确率：$\frac{|Pred(u)\cap True(u)|}{|Pred(u)|}$

• 覆盖率：$\frac{|Pred(u)|}{|I|}$预测物品占所有物品的比例

• 新颖度：推荐列表中物品的平均流行度度量推荐结果的新颖度

### 缺陷

泛化能力弱：无法将两个物品相似的信息推广到其他物品的相似性上。 导致热门物品具有很强的头部效应， 容易跟大量物品产生相似， 而尾部物品由于特征向量稀疏， 导致很少被推荐

无外部信息：没有利用到物品本身或者是用户自身的属性， 仅仅利用了用户与物品的交互信息就可以实现推荐，忽略有效信息

## 矩阵分解

矩阵分解算法将 m×n 维的共享矩阵R分解成 m×k 维的用户矩阵U和 k×n 维的物品矩阵V相乘的形式。 其中m是用户数量，n是物品数量，k是隐向量维度
$$
p_{i,j}=\sum _k u_{i,k}*v_{k, j}
$$
使用传统的SVD分解的方法需要对稀疏矩阵的缺失值进行补全，这种方法计算复杂度高，且补全值不精确，无法使用。常用的矩阵分解方法是给定用户矩阵于物品矩阵的初值，转化矩阵分解问题为最优化问题，通过梯度下降的方法进行求解
$$
SSE=\sum_{i,j}e_{i,j}^2=\sum_{i,j}(r_{i,j}-\sum _k u_{i,k}*v_{k, j})^2
$$
在实际应用中，有些固有的属性和用户物品无关， 而用户也有些属性和物品无关， 物品也有些属性和用户无关。 在基础模型中加入偏置项， 可以消除用户和物品打分的偏差
$$
\hat p_{i,j}=\mu + b_u + b_i + \sum _k u_{i,k}*v_{k, j}
$$
• $\mu$ : 训练集中所有记录的评分的全局平均数

• $b_u$: 用户偏差系数， 可以使用用户u给出的所有评分的均值， 也可以当做训练参数

• $b_i$ : 物品偏差系数， 可以使用物品i收到的所有评分的均值， 也可以当做训练参数

矩阵分解算法相比协同过滤方法而言，泛化能力强，在一定程度上解决了矩阵稀疏问题，同时仅需要储存用户矩阵于物品矩阵，空间复杂度有所降低，同时可以学习到一些隐特征；但是矩阵分解算法没有用到用户属性和物品属性，损失了部分有效信息

## 用户画像

用户画像就是与该用户相关联的数据的可视化的展现，一句话来总结就是用户信息标签化。从用户海量的信息里面去找到一些标签，为用户去贴上这些标签，当然这些标签的来源就是一些用户的行为。

### 作用

（1）精准营销：根据历史用户特征，分析产品的潜在用户和用户的潜在需求，针对特定群体，利用短信、邮件等方式进行营销。

（2）用户统计：根据用户的属性、行为特征对用户进行分类后，统计不同特征下的用户数量、分布；分析不同用户画像群体的分布特征。

（3）数据挖掘：以用户画像为基础构建推荐系统、搜索引擎、广告投放系统，提升服务精准度。

（4）服务产品：对产品进行用户画像，对产品进行受众分析，更透彻地理解用户使用产品的心理动机和行为习惯，完善产品运营，提升服务质量。

（5）行业报告&用户研究：通过用户画像分析可以了解行业动态，比如人群消费习惯、消费偏好分析、不同地域品类消费差异分析

### 数据需求

（1）人口属性：包括性别、年龄等人的基本信息

（2）兴趣特征：浏览内容、收藏内容、阅读咨询、购买物品偏好等

（3）消费特征：与消费相关的特征

（4）位置特征：用户所处城市、所处居住区域、用户移动轨迹等

（5）设备属性：使用的终端特征等

（6）行为数据：访问时间、浏览路径等用户在网站的行为日志数据

（7）社交数据：用户社交相关数据

## 因子分解机FM

普通的线性模型，我们都是将各个特征独立考虑的，并没有考虑到特征与特征之间的相互关系。但实际上，特征之间可能具有一定的关联。 