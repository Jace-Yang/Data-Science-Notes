# 机器学习面经整理（持续更新）

## ML基础概念类

### 基础

1.overfitting/underfiting是指的什么

过拟合：模型过于复杂，泛化误差高，在训练数据集上表现好，在测试数据集上表现差

欠拟合：模型过于简单，训练误差高，在训练数据集和测试数据集上表现差

2.bias/variance trade off 是指的什么

**偏差**度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力

**方差**度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响

学习器的泛化误差可以分解为偏差+方差+噪声

![img](https://pic3.zhimg.com/80/v2-76559095430dc32202d57d8177aeb572_1440w.jpg)

偏差小的模型，方差大；方差小的模型，偏差大；存在一个偏差与方差都较低的点，此时模型泛化误差最小

3.欠拟合，过拟合一般有哪些预防手段

**解决欠拟合的方法：**

```text
1、增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间
2、尝试非线性模型，比如核SVM 、决策树、DNN等模型
3、如果有正则项可以较小正则项参数 lambda
4、Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等
```

**解决过拟合的方法：**

```text
1、交叉检验，通过交叉检验得到较优的模型参数
2、特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间
3、正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择
4、如果有正则项则可以考虑增大正则项参数 lambda
5、增加训练数据可以有限的避免过拟合
6、Bagging ,将多个弱学习器Bagging 一下效果会好很多，比如随机森林等
```

4.Generative和Discrimitive的区别

Generative: 求联合概率分布$P(X, Y)$，利用贝叶斯公式求条件概率分布$P(Y|X)=\frac{P(X,Y)}{P(X)}$

Discrimitive: 直接求条件概率分布$P(Y|X)$

![img](https://pic1.zhimg.com/80/v2-a2e753542fc6384ee351cabdbe6dd523_1440w.jpg?source=1940ef5c)

5.Give a set of ground truths and 2 models, how do you be confident that one model is better than another?

使用模型预测的准确率、精确率、召回率、平方误差率等指标进行评判

期望风险：模型在预测数据集上的表现

经验风险：模型在训练数据集上的表现

结构风险：模型的复杂程度

期望风险难求，用经验风险和结构风险之和近似

### Reguarlization

1.L1 vs L2, which one is which and difference

正则化项是模型的结构风险，通过最小化结构风险避免模型发生严重的过拟合，目标函数为原始目标函数加正则化项，正则化项如下
$$
\lambda \sum_{i=1}^{M}|w_j|^q
$$
q=1，L1正则化，可以得到稀疏解，通过近端梯度下降等方法求解

q=2，L2正则化，求导梯度下降求解最优值，无法得到稀疏解

如下图所示，求解目标函数最小值，原始目标函数为蓝圈，正则化项为红圈，相交点处目标函数最小

![img](https://pic4.zhimg.com/80/v2-4a49a0ef8dacba6da8c77bc7d24dd9f0_1440w.jpg?source=1940ef5c)

2.Lasso/Ridge的解释 (prior分别是什么）

Lasso: 线性回归+L1正则化项，等价于给线性回归加拉普拉斯先验
$$
J=\frac{1}{n}\sum_{i=1}^n(f(x_i)-y_i)^2+\lambda||w||_1
$$
Ridge: 线性回归+L2正则化项，等价于给线性回归加高斯先验
$$
J=\frac{1}{n}\sum_{i=1}^n(f(x_i)-y_i)^2+\lambda||w||^2_2
$$
最大后验估计：
$$
P(\theta|y)=\frac{P(y|\theta)P(\theta)}{P(y)}
$$

$$
\theta=arg max P(\theta|y)=argmaxP(y|\theta)P(\theta)
$$

$P(\theta)$为事先引入的先验知识，$P(y|\theta)$服从正态分布

3.为什么regularization works

限制模型的复杂度，使得部分参数较小或者为零，减小模型的结构风险

4.为什么regularization用L1 L2，而不是L3, L4..

L1正则化可以得到稀疏解，L2正则化有唯一解，L3，L4正则化倒数为高次多项式，存在多个零点，可能有多个最小值

### Metric

1.分类问题评判标准

TP：True Positive ：做出Positive的判定，而且判定是正确的
FP：False Positive ：做出Positive的判定，而且判定是错误的
TN：True Negative ：正确的Negative判定
FN：False Negative：错误的Negative判定

准确率Accuracy：TP+TN/TP+FP+TN+FN

精确率Precision：TP/TP+FP

召回率Recall：TP/TP+FN

F1得分：1/F1 = 1/P + 1/R

ROC曲线与AUC值

ROC曲线按照排序的顺序逐一按照正例预测，以“真正例率”（True Positive Rate，简称TPR）为纵轴，横轴为“假正例率”（False Positive Rate，简称FPR），ROC偏重研究基于测试样本评估值的排序好坏，AUC值即为ROC曲线下的面积，当AUC>0.5时，说明分类器有效，AUC=0.5时相当于随机猜测，AUC<0.5时，负向预测有效
$$
TPR=\frac{TP}{TP+FN}
$$

$$
FPR=\frac{FP}{TN+FP}
$$

![13.png](https://i.loli.net/2018/10/17/5bc71ed75cefe.png)

如下图所示，真正例与真负例服从分布，若两个分布无重叠，AUC=1，有重叠时AUC<1

![Image for post](https://miro.medium.com/max/1014/1*yF8hvKR9eNfqqej2JnVKzg.png)

2.label 不平衡时用什么metric

精确率、召回率、F1得分：精确率与召回率考虑了模型预测的查准、查全

AUC-ROC曲线：AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价

3.回归问题评判标准

MSE：平均平方误差
$$
MSE=\frac{1}{n}\sum_{i=1}^n||y_i-\hat y_i||_2^2
$$
MAE：平均绝对误差
$$
MAE=\frac{1}{n}\sum_{i=1}^n|y_i-\hat y_i|
$$
可决系数R方：反映自变量x对因变量y的可解释程度



4.confusion matrix

![5.png](https://i.loli.net/2018/10/17/5bc71daf871a6.png)

 

### Loss与优化

1.用MSE做loss的Logistic Rregression是convex problem吗

非凸优化问题

2.解释并写出MSE的公式, 什么时候用到MSE?
$$
MSE=\frac{1}{n}\sum_{i=1}^n(x_i-\hat x_i)^2
$$
MSE用于评判回归模型的效果

3.Linear Regression最小二乘法和MLE关系

最小二乘法通过最小化平均平方误差来得到参数值，MLE通过最大化似然函数值来得到参数值，这两种最终求得的LOSS function是相同的

4.什么是relative entropy/cross entropy, 以及K-L divergence 他们intuition

相对熵即K-L散度，衡量两个事件/分布的不同
$$
D_{KL}(A||B)=\sum_i-P_A(x_i)log(P_B(x_i))-\sum_i-P_A(x_i)log(P_A(x_i))=\sum_i P_A(x_i)log(\frac{P_A(x_i)}{P_B(x_i)})
$$

交叉熵为相对熵公式前半部分
$$
\sum_i-P_A(x_i)log(P_B(x_i))
$$
在机器学习问题中，$P_A(x_i)$为真实分布，$P_B(x_i)$为近似分布，相对熵后半部分为常数，相对熵达到最小值的时候，也意味着交叉熵达到了最小值。对$P_B(x_i)$的优化就等效于求交叉熵的最小值。另外，对交叉熵求最小值，也等效于求最大似然估计


## DL基础概念类

### 神经网络结构

1.DNN为什么要有bias term, bias term的intuition是什么

bias term可以使得我们分类的直线平移，增加了一个自由度，更加灵活，也可以视作激活函数的阈值

2.什么是Back Propagation

神经网络中根据链式法则，误差项反向传播，计算最终结果的误差对各个节点的导数，从而对整个网络的所有节点的参数值进行优化

3.梯度消失和梯度爆炸是什么，怎么解决

深度神经网络在反向传播过程中，多层的导数相乘，若每层的导数较大，则会发生梯度爆炸，最终结果很大。若每层导数较小，则会发生梯度消失，最终结果很小

常用的解决方法有更换激活函数、batchnorm、采用残差结构等

Relu激活函数的导数恒为1，不存在梯度消失和梯度爆炸的问题

Batchnorm对每一层的输出进行标准化，保证均值和方差一致

残差网络对上一层预测的残差进行训练，解决了梯度消失和爆炸的问题

4.神经网络初始化能不能把weights都initialize成0

不能，因为如果将权值初始化为 0 ，或者其他统一的常量，会导致后面的激活单元具有相同的值，所有的单元相同意味着它们都在计算同一特征，网络变得跟只有一个隐含层节点一样，这使得神经网络失去了学习不同特征的能力

5.DNN和Logistic Regression的区别

逻辑回归可以看作只有一个神经元的神经网络，深度神经网络通过增加神经元的个数获取更多隐藏在变量当中的信息，拟合能力强

6.common activation functions （sigmoid, tanh, relu, leaky relu） 是什么以及每个的优缺点

sigmoid 函数 ：$a=\frac{1}{1+e^{-z}}$

常用的激活函数，也是逻辑回归中的激活函数，当z趋近于无穷时，梯度趋近于0，可能会有梯度消失问题，在梯度下降时，收敛速度很慢

tanh 函数（the hyperbolic tangent function，双曲正切函数）：$a = \frac{e^z - e^{-z}}{e^z + e^{-z}}$

效果通常好于sigmoid函数，值域在-1到1之间，有数据中心化的效果，当z趋近于无穷时，梯度趋近于0，可能会有梯度消失问题，在梯度下降时，收敛速度很慢

ReLU 函数（the rectified linear unit，修正线性单元）：$a=max(0,z)$

当 z > 0 时，梯度始终为 1，从而提高神经网络基于梯度算法的运算速度，收敛速度远大于 sigmoid 和 tanh。然而当 z < 0 时，梯度一直为 0

Leaky ReLU（带泄漏的 ReLU）：$a=max(0.01z,z)$

Leaky ReLU 保证在 z < 0 的时候，梯度仍然不为 0。理论上来说，Leaky ReLU 有 ReLU 的所有优点，但在实际操作中没有证明总是好于 ReLU，因此不常用

![image-20210320125820099](/Users/zhangjingxiang/Library/Application Support/typora-user-images/image-20210320125820099.png)

7.为什么需要non-linear activation functions

使用线性激活函数和不使用激活函数、直接使用 Logistic 回归没有区别，那么无论神经网络有多少层，输出都是输入的线性组合，与**没有隐藏层**效果相当

### 优化问题

1.how to do hyperparameter tuning in DL

Random search：随机搜索，在参数空间中随机选择参数组合，计算效率相比网格搜索更高

Grid search：网格搜索，M个参数，每个参数有N个候选值，尝试$M^N$种不同的参数组合

2.Deep Learning有哪些预防overfitting的办法

适用于传统机器学习算法解决过拟合问题的方法同样适用于深度学习

除此之外深层神经网络还可以采用Dropout、Early stopping、Data Augmentation等方法解决过拟合

Dropout: 神经网络的每个单元都被赋予在计算中被暂时忽略的概率p。超参数p称为丢失率，通常将其默认值设置为0.5。然后，在每次迭代中，根据指定的概率随机选择丢弃的神经元。因此，每次训练会使用较小的神经网络，这种方法减小了模型的复杂度。

训练模型阶段：在训练网络的每个单元都要添加一道概率流程，以一定概率舍弃某个神经元，同时对权重进行缩放，乘概率 $\frac{1}{1-p}$

测试模型阶段：用所有神经元参与计算

Early stopping：在用梯度下降法的过程中，在模型开始过拟合之前就中断学习过程

数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集

3.常用的优化方法

Batch Gradient Descend：最常用的梯度下降形式，即同时处理整个训练集；每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢

Mini-batch Gradient Descend：每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。

Stochastic Gradient Descend：对每一个训练样本执行一次梯度下降，训练速度快

![image-20210320131646991](/Users/zhangjingxiang/Library/Application Support/typora-user-images/image-20210320131646991.png)

Batch梯度下降对所有样本做一次梯度下降，每次的迭代时间较长；Mini-batch梯度下降使用部分样本做梯度下降，兼容了模型的训练速度和梯度下降方向的准确性；随机梯度下降对每个样本进行一次梯度下降，速度最快，但噪声较大，且永远不会收敛

4.梯度下降的优化器

动量梯度下降（Gradient Descent with Momentum）：计算梯度的指数加权平均数，并利用该值来更新参数值

$$v_{dW^{[l]}} = \beta v_{dW^{[l]}} + (1 - \beta) dW^{[l]}$$

$$v_{db^{[l]}} = \beta v_{db^{[l]}} + (1 - \beta) db^{[l]}$$

$$W^{[l]} := W^{[l]} - \alpha v_{dW^{[l]}}$$ 

$$b^{[l]} := b^{[l]} - \alpha v_{db^{[l]}}$$

![image-20210320132626601](/Users/zhangjingxiang/Library/Application Support/typora-user-images/image-20210320132626601.png)

使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线

RMSProp（Root Mean Square Propagation，均方根传播）：在对梯度进行指数加权平均的基础上，引入平方和平方根。RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度

$$s_{dw} = \beta s_{dw} + (1 - \beta)(dw)^2$$

$$s_{db} = \beta s_{db} + (1 - \beta)(db)^2$$ 

$$w := w - \alpha \frac{dw}{\sqrt{s_{dw} + \epsilon}}$$

$$b := b - \alpha \frac{db}{\sqrt{s_{db} + \epsilon}}$$

Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）：将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。

$$v_{dW} = \beta_1 v_{dW} + (1 - \beta_1) dW$$ 

$$v_{db} = \beta_1 v_{db} + (1 - \beta_1) db$$

$$s_{dW} = \beta_2 s_{dW} + (1 - \beta_2) {(dW)}^2$$ 

$$s_{db} = \beta_2 s_{db} + (1 - \beta_2) {(db)}^2$$

$$v^{corrected}_{dW} = \frac{v_{dW}}{1-{\beta_1}^t}$$ 

$$v^{corrected}_{db} = \frac{v_{db}}{1-{\beta_1}^t}$$

$$s^{corrected}_{dW} = \frac{s_{dW}}{1-{\beta_2}^t}$$ 

$$s^{corrected}_{db} = \frac{s_{db}}{1-{\beta_2}^t}$$

$$W := W - \alpha \frac{v^{corrected}_{dW}}{{\sqrt{s^{corrected}_{dW}} + \epsilon}}$$

$$b := b - \alpha \frac{v^{corrected}_{db}}{{\sqrt{s^{corrected}_{db}} + \epsilon}}$$

5.learning rate过大过小对于模型的影响

学习率过小，学习速度较慢，较多时间才能获得最优解

学习率过大，可能会错过最优解，梯度下降过程不收敛

6.Problem of Plateau, saddle point

**鞍点（saddle）**是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是下图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。

![image-20210320134117557](/Users/zhangjingxiang/Library/Application Support/typora-user-images/image-20210320134117557.png) 

## ML模型类

### Regression

1.Linear Regression的基础假设是什么

线性性：因变量和自变量满足线性关系

独立性（误差项）：误差项之间相互独立

独立性（自变量）：各个自变量之间相互独立

正态性：误差项应呈正态分布

同方差性：误差项的方差为常数

2.what will happen when we have correlated variables, how to solve

删除变量：这个方法一般不推荐使用，因为删除变量会导致异方差增大

增加样本容量：增大样本量，减小多重共线性

变换模型：对数据求差分；计算相对指标；相关变量做线性组合，例如使用主成分分析等方法降维

逐步回归：常用方法，添加删除变量之后做可决系数、F检验和T检验来确定是否增加或者剔除变量，若果增加变量对这些指标的影响较小，也认为指标为多余的，如果增加指标引起R和F的变动且通不过T检验，说明存在共线性

岭回归：Ridge regression加入正则化项，减小自变量系数，减弱多重共线性

3.explain regression coefficient

回归分析只能得出相关关系，不能判断因果关系

当其他变量保持不变或控制其他变量不变时$X$每改变一个单位时因变量$Y$的平均变化量

4.what is the relationship between minimizing squared error and maximizing the likelihood

两种不同的求最优解的方法，最终计算出的结果是一致的

最小二乘法(OLS)基于频率派概率思想，求真值与估计值之间差值最小对应的参数

最大似然(MLE)基于贝叶斯思想，将参数看作概率分布，通过最大化似然函数来求参数

5.if the relationship between y and x is no linear, can linear regression solve that

可以添加高次变量，以及不同变量之间的组合，例如$x_1^2$ $x_1x_2$等交互变量作为自变量

6.Logistic Regression的loss是什么

logistic regression的损失函数为交叉熵损失函数
$$
J(\theta)=-[ylog(h(x))+(1-y)log(1-h(x))]
$$

### SVM支持向量积

1.Explain SVM, 如何引入非线性

支持向量机（support vector machines, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。

对于输入空间中的非线性分类问题，可以通过非线性变换将它转化为某个维特征空间中的线性分类问题，在高维特征空间中学习线性支持向量机

2.Explain kernel methods, why to use

在线性支持向量机学习的对偶问题里，目标函数和分类决策函数都只涉及实例和实例之间的内积，所以不需要显式地指定非线性变换**，**而是用核函数替换当中的内积。
$$
K(x,z)=\phi (x)\sdot\phi(z)
$$
3.what kernels do you know

![img](https://pic1.zhimg.com/80/v2-31c10f29156c5acedafda70524d8eb00_1440w.jpg)

4.怎么把SVM的output按照概率输出

SVM分类器能输出（测试）样本和决策边界的距离，可以把这个距离当做一个置信度数值。可以用Logistic Regression把SVM输出的置信度数值校准为概率值

### Decision Tree

1.How regression/classification DT split nodes?

CART:分类树与回归树算法，CART假设决策树是二叉树，内部节点特征的取值为是和否，左分支为取值为是的分支，右分支为取值为否的分支，使用基尼系数来选择最优变量的最优拆分点

回归树：回归树的训练过程采用启发式的方法选择第i个变量和他的切分点s，通过最小化误差函数的方法选择最优切分变量和切分点，每个节点样本的均值作为测试样本的回归预测值

分类树：计算现有特征对数据集的基尼指数，在所有特征和切分点中选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点，每个节点样本的类别情况投票决定测试样本的类别

2.How to prevent overfitting in DT?

可以通过预剪枝或者后剪枝的方法预防过拟合

预剪枝策略：

定义一个高度，当决策树达到该高度时就可以停止决策树的生长

达到某个结点的实例具有相同的特征向量，即使这些实例不属于同一类，也可以停止决策树的生长

定义一个阈值，当达到某个结点的实例个数小于该阈值时就可以停止决策树的生长

定义一个阈值，通过计算每次扩张对系统性能的增益，并比较增益值与该阈值的大小来决定是否停止决策树的生长

后剪枝策略：删除一些子树，然后用其叶子节点代替

REP方法是一种比较简单的后剪枝的方法，在该方法中，可用的数据被分成两个样例集合：一个训练集用来形成学习到的决策树，一个分离的验证集用来评估这个决策树在后续数据上的精度，确切地说是用来评估修剪这个决策树的影响

PEP,悲观错误剪枝,悲观错误剪枝法是根据剪枝前后的错误率来判定子树的修剪

3.How to do regularization in DT?

通过设置最大深度，节点分裂阈值等方法来完成正则化

4.Decision Tree split node的时候优化目标是啥

回归树最小化平均平方误差，分类树最小化基尼指数

### Ensemble Learning集成学习

1.difference between bagging and boosting

样本选择上：

Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的

Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整

样例权重：

Bagging：使用均匀取样，每个样例的权重相等

Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大

预测函数：

Bagging：所有预测函数的权重相等

Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重

并行计算：

Bagging：各个预测函数可以并行生成

Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果

2.gbdt和random forest 区别，pros and cons

随机森林采用的bagging思想，而GBDT采用的boosting思想

组成随机森林的树可以是分类树，也可以是回归树；而GBDT只能由回归树组成

组成随机森林的树可以并行生成；而GBDT只能是串行生成

对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来

随机森林对异常值不敏感；GBDT对异常值非常敏感

随机森林对训练集一视同仁；GBDT是基于权值的弱分类器的集成

随机森林是通过减少模型方差提高性能；GBDT是通过减少模型偏差提高性能

3.will random forest help reduce bias or variance/why random forest can help reduce variance

随机森林随机选择数据集和特征，特征数量小于总特征，多个分类器的平均结果就是最终预测的结果，而多个分类器的方差相似，去平均后方差为原来的1/n，所以随机森林可以减小方差，但是均值与单个模型的均值相同，所以不能减小偏差

通常来说boosting是在优化loss function，在降低loss，那么很显然，这在很大程度上是减少bias。
而bagging，之所以进行bagging，是希望模型能够具有更好的鲁棒性，也就是稳定性，希望避免过拟合，显然这就是在减少variance

### Clustering and EM:

1.K-means clustering (explain the algorithm in detail; whether it will converge, 收敛到global or local optimums; how to stop)

优化目标是最小化点与类别中心点之间距离的平方和

首先选取类别个数k并初始化类别中心，计算点到类别中心的距离并将其归入距离最小的类别，重新计算类别中心并反复迭代；当某次迭代与上一次迭代后所有点的类别都没有发生改变，则聚类停止

k均值聚类最终的类别划分与初始聚类中心的选择有关，收敛到局部最小值，可以尝试选择不同初始值进行聚类

2.K-means与KNN的区别

K-Means是无监督学习的聚类算法，没有样本输出；而KNN是监督学习的分类算法，有对应的类别输出。KNN基本不需要训练，对测试集里面的点，只需要找到在训练集中最近的k个点，用这最近的k个点的类别来决定测试点的类别。而K-Means则有明显的训练过程，找到k个类别的最佳质心，从而决定样本的簇类别。

3.EM算法是什么

对于含有隐变量的模型，极大似然法不方便求解，通过Jensen不等式进行放缩，极大化似然函数的下界，E步求期望，M步求期望的极大值来得到新的参数，这样反复迭代后，求出最优解

4.GMM是什么，和Kmeans的关系

K-means算法可以被视为高斯混合模型（GMM）的一种特殊形式。整体上看，高斯混合模型能提供更强的描述能力，因为聚类时数据点的从属关系不仅与近邻相关，还会依赖于类簇的形状。n维高斯分布的形状由每个类簇的协方差来决定。在协方差矩阵上添加特定的约束条件后，可能会通过GMM和k-means得到相同的结果。

### 降维

1.Explain PCA

主成分分析是一种统计分析、简化数据集的方法。它利用正交变换来对一系列可能相关的变量的观测值进行线性变换，从而投影为一系列线性不相关变量的值，这些不相关变量称为主成分

2.LDA是什么，假设是什么

LDA算法的思想是将数据投影到低维空间之后，使得同一类数据尽可能的紧凑，不同类的数据尽可能分散。与PCA不同的是，LDA是一种监督学习方法

## 数据处理类

1.怎么处理imbalanced data

欠采样：去除训练集内一些多数样本，使得两类数据量级接近，然后在正常进行学习，这种方法可能会损失一部分的样本信息，比较适合在样本数量较大的时候使用

过采样：对训练集内的少数样本进行扩充，既增加少数样本使得两类数据数目接近，然后再进行学习，这种方法会增加一些重复信息，容易造成过拟合，在数据量较小的时候使用

样本加权：对样本中的少数样本赋予更高的权重

尝试不同的算法：决策树类算法对不平衡样本的表现较好

2.missing data如何处理

用平均值、中值、分位数、众数、随机值等替代

用其他变量做预测模型来算出缺失变量

删除有缺失值的变量

对于随机森林等模型，缺失值不会影响模型效果

3.how to do feature selection

过滤法：计算自变量和因变量的相关系数、互信息、卡方值等，筛选出相关性比较大的变量

包装法：对于每个待选子集，都在训练集上训练一遍模型，然后在测试集上根据误差大小选择出特征子集。这种方法通常有前向法（从1个特征开始，逐次引入新特征，并计算错误率）、后向法（从所有特征开始，逐次剔除特征，并计算错误率）、前向-后向法（结合前向与后向）

嵌入法：通过加入正则化项来做特征选择，L1正则化可以求出稀疏解，实现特征选择的目的

## DL模型类（待更新）

### NLP/RNN相关

LSTM的公式是什么

why use RNN/LSTM

LSTM比RNN好在哪

limitation of RNN

How to solve gradient vanishing in RNN

What is attention, why attention

Language Model的原理，N-Gram Model

What’s CBOW and skip-gram?

什么是Word2Vec， loss function是什么， negative sampling是什么

### CNN/CV相关

maxpooling， conv layer是什么, 为什么做pooling，为什么用conv lay，什么是equivariant to-translationa, 

invariant to translation

1x1 filter

什么是skip connection
