## 卷积运算

1.二维卷积

卷积运算的求解过程是从左到右，由上到下，每次在原始图片矩阵中取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，将结果组成一个矩阵。

假设输入图片的大小为$n×n$，而滤波器的大小为$f×f$，则卷积后的输出图片大小为$(n−f+1)×(n−f+1)$

![img](http://www.ai-start.com/dl2017/images/f889ad7011738a23d78070e8ed2df04e.png)

普通卷积运算存在的问题是：每次卷积运算后，输出图片的尺寸缩小；原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。为了解决这个问题，在进行卷积操作前，对原始图片在边界上进行**填充（Padding）**，以增加矩阵的大小。通常将 0 作为填充值。

设每个方向扩展像素点数量为$p$，则填充后原始图片的大小为$(n+2p)×(n+2p)$，滤波器大小保持$f×f$不变，则输出图片大小为 $(n+2p−f+1)×(n+2p−f+1)$

卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置**步长（Stride）**来压缩一部分信息。
$$
⌊\frac{n+2p−f}{s}+1⌋×⌊\frac{n+2p−f}{s}+1⌋
$$
2.三维卷积

如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。

![img](http://www.ai-start.com/dl2017/images/d148c3dd7ce9e6d7e29c02c483298842.png)

如果想同时检测垂直和水平边缘，或者更多的边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。设输入图片的尺寸为$n×n×n_c$（$n_c$为通道数），滤波器尺寸为$f×f×n_c$，则卷积后的输出图片尺寸为$ (n−f+1)×(n−f+1)×n′_c$，$n′_c$为滤波器组的个数。

![img](http://www.ai-start.com/dl2017/images/794b25829ae809f93ac69f81eee79cd1.png)

3.卷积操作的原理

- **参数共享（Parameter sharing）**：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。
- **稀疏连接（Sparsity of connections）**：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。

## 卷积神经网络

1.简单卷积神经网络

与之前的卷积过程相比较，卷积神经网络的单层结构多了激活函数和偏移量。随着神经网络计算深度不断加深，图片的高度和宽度 $n_H$、$n_W$一般逐渐减小，而$n_c$在增加。

对于一个 3x3x3 的滤波器，包括偏移量 bb在内共有 28 个参数。不论输入的图片有多大，用这一个滤波器来提取特征时，参数始终都是 28 个，固定不变。即**选定滤波器组后，参数的数目与输入图片的尺寸无关**。因此，卷积神经网络的参数相较于标准神经网络来说要少得多。这是 CNN 的优点之一。

![img](http://www.ai-start.com/dl2017/images/0c09c238ff2bcda0ddd9405d1a60b325.png)

2.池化层

卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性

**最大池化（Max Pooling）**：将输入拆分成不同的区域，输出的每个元素都是对应区域中元素的最大值

**平均池化（Average Pooling）**：从取某个区域的最大值改为求这个区域的平均值

![img](http://www.ai-start.com/dl2017/images/ac42ede86634922acf4d34b12025b34f.png)