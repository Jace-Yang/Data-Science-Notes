## ML基础概念类

### 基础

1.overfitting/underfiting是指的什么

过拟合：模型过于复杂，泛化误差高，在训练数据集上表现好，在测试数据集上表现差

欠拟合：模型过于简单，训练误差高，在训练数据集和测试数据集上表现差

2.bias/variance trade off 是指的什么

**偏差**度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力

**方差**度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响

学习器的泛化误差可以分解为偏差+方差+噪声

![img](https://i.loli.net/2021/08/02/HRwP1uQhVj9zEqo.jpg)

偏差小的模型，方差大；方差小的模型，偏差大；存在一个偏差与方差都较低的点，此时模型泛化误差最小

3.欠拟合，过拟合一般有哪些预防手段

**解决欠拟合的方法：**

```text
1、增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间
2、尝试非线性模型，比如核SVM 、决策树、DNN等模型
3、如果有正则项可以较小正则项参数 lambda
4、Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等
```

**解决过拟合的方法：**

```text
1、交叉检验，通过交叉检验得到较优的模型参数
2、特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间
3、正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择
4、如果有正则项则可以考虑增大正则项参数 lambda
5、增加训练数据可以有限的避免过拟合
6、Bagging ,将多个弱学习器Bagging 一下效果会好很多，比如随机森林等
```

4.Generative和Discrimitive的区别

Generative: 求联合概率分布$P(X, Y)$，利用贝叶斯公式求条件概率分布$P(Y|X)=\frac{P(X,Y)}{P(X)}$

Discrimitive: 直接求条件概率分布$P(Y|X)$

![img](https://i.loli.net/2021/08/02/Sbs79dz2qLZrth8.jpg)

5.Give a set of ground truths and 2 models, how do you be confident that one model is better than another?

使用模型预测的准确率、精确率、召回率、平方误差率等指标进行评判

期望风险：模型在预测数据集上的表现

经验风险：模型在训练数据集上的表现

结构风险：模型的复杂程度

期望风险难求，用经验风险和结构风险之和近似

### Reguarlization

1.L1 vs L2, which one is which and difference

正则化项是模型的结构风险，通过最小化结构风险避免模型发生严重的过拟合，目标函数为原始目标函数加正则化项，正则化项如下
$$
\lambda \sum_{i=1}^{M}|w_j|^q
$$
q=1，L1正则化，可以得到稀疏解，通过近端梯度下降等方法求解

q=2，L2正则化，求导梯度下降求解最优值，无法得到稀疏解

如下图所示，求解目标函数最小值，原始目标函数为蓝圈，正则化项为红圈，相交点处目标函数最小

![img](https://i.loli.net/2021/08/02/CL84sPApiofEzGX.jpg)

2.Lasso/Ridge的解释 (prior分别是什么）

Lasso: 线性回归+L1正则化项，等价于给线性回归加拉普拉斯先验
$$
J=\frac{1}{n}\sum_{i=1}^n(f(x_i)-y_i)^2+\lambda||w||_1
$$
Ridge: 线性回归+L2正则化项，等价于给线性回归加高斯先验
$$
J=\frac{1}{n}\sum_{i=1}^n(f(x_i)-y_i)^2+\lambda||w||^2_2
$$
最大后验估计：
$$
P(\theta|y)=\frac{P(y|\theta)P(\theta)}{P(y)}
$$

$$
\theta=arg max P(\theta|y)=argmaxP(y|\theta)P(\theta)
$$

$P(\theta)$为事先引入的先验知识，$P(y|\theta)$服从正态分布

3.为什么regularization works

限制模型的复杂度，使得部分参数较小或者为零，减小模型的结构风险

4.为什么regularization用L1 L2，而不是L3, L4..

L1正则化可以得到稀疏解，L2正则化有唯一解，L3，L4正则化倒数为高次多项式，存在多个零点，可能有多个最小值

### Metric

1.分类问题评判标准

TP：True Positive ：做出Positive的判定，而且判定是正确的
FP：False Positive ：做出Positive的判定，而且判定是错误的
TN：True Negative ：正确的Negative判定
FN：False Negative：错误的Negative判定

准确率Accuracy：TP+TN/TP+FP+TN+FN

精确率Precision：TP/TP+FP

召回率Recall：TP/TP+FN

F1得分：1/F1 = 1/P + 1/R

ROC曲线与AUC值

ROC曲线按照排序的顺序逐一按照正例预测，以“真正例率”（True Positive Rate，简称TPR）为纵轴，横轴为“假正例率”（False Positive Rate，简称FPR），ROC偏重研究基于测试样本评估值的排序好坏，AUC值即为ROC曲线下的面积，当AUC>0.5时，说明分类器有效，AUC=0.5时相当于随机猜测，AUC<0.5时，负向预测有效
$$
TPR=\frac{TP}{TP+FN}
$$

$$
FPR=\frac{FP}{TN+FP}
$$

![13.png](https://i.loli.net/2018/10/17/5bc71ed75cefe.png)

如下图所示，真正例与真负例服从分布，若两个分布无重叠，AUC=1，有重叠时AUC<1

![Image for post](https://i.loli.net/2021/08/02/IckhsWpVL8TDnYi.png)

2.label 不平衡时用什么metric

精确率、召回率、F1得分：精确率与召回率考虑了模型预测的查准、查全

AUC-ROC曲线：AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价

3.回归问题评判标准

MSE：平均平方误差
$$
MSE=\frac{1}{n}\sum_{i=1}^n||y_i-\hat y_i||_2^2
$$
MAE：平均绝对误差
$$
MAE=\frac{1}{n}\sum_{i=1}^n|y_i-\hat y_i|
$$
可决系数R方：反映自变量x对因变量y的可解释程度



4.confusion matrix

![5.png](https://i.loli.net/2018/10/17/5bc71daf871a6.png)

 

### Loss与优化

1.用MSE做loss的Logistic Rregression是convex problem吗

非凸优化问题

2.解释并写出MSE的公式, 什么时候用到MSE?
$$
MSE=\frac{1}{n}\sum_{i=1}^n(x_i-\hat x_i)^2
$$
MSE用于评判回归模型的效果

3.Linear Regression最小二乘法和MLE关系

最小二乘法通过最小化平均平方误差来得到参数值，MLE通过最大化似然函数值来得到参数值，这两种最终求得的LOSS function是相同的

4.什么是relative entropy/cross entropy, 以及K-L divergence 他们intuition

相对熵即K-L散度，衡量两个事件/分布的不同
$$
D_{KL}(A||B)=\sum_i-P_A(x_i)log(P_B(x_i))-\sum_i-P_A(x_i)log(P_A(x_i))=\sum_i P_A(x_i)log(\frac{P_A(x_i)}{P_B(x_i)})
$$

交叉熵为相对熵公式前半部分
$$
\sum_i-P_A(x_i)log(P_B(x_i))
$$
在机器学习问题中，$P_A(x_i)$为真实分布，$P_B(x_i)$为近似分布，相对熵后半部分为常数，相对熵达到最小值的时候，也意味着交叉熵达到了最小值。对$P_B(x_i)$的优化就等效于求交叉熵的最小值。另外，对交叉熵求最小值，也等效于求最大似然估计